<!DOCTYPE html>
<html lang="en">

<head><meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">
<meta http-equiv="Accept-CH" content="DPR, Viewport-Width, Width">
<link rel="icon" href=favicon_dh.ico type="image/gif">


<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link rel="preload"
      as="style"
      href="https://fonts.googleapis.com/css2?family=Alata&family=Lora:ital,wght@0,400;0,500;0,600;0,700;1,400;1,500;1,600;1,700&family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&display=swap"
>
<link rel="stylesheet"
      href="https://fonts.googleapis.com/css2?family=Alata&family=Lora:ital,wght@0,400;0,500;0,600;0,700;1,400;1,500;1,600;1,700&family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&display=swap"
      media="print" onload="this.media='all'" />
<noscript>
  <link
          href="https://fonts.googleapis.com/css2?family=Alata&family=Lora:ital,wght@0,400;0,500;0,600;0,700;1,400;1,500;1,600;1,700&family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&display=swap"
          rel="stylesheet">
</noscript>


<link rel="stylesheet" href="/css/font.css" media="all">



<meta property="og:url" content="https://hhook.github.io/blogs/07_helena_chatbot/">
  <meta property="og:site_name" content="Datahook: Helena">
  <meta property="og:title" content="Building an AI version of myself">
  <meta property="og:description" content="How I built a persona-based LLM chatbot with self-evaluation.">
  <meta property="og:locale" content="en_us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="blogs">
    <meta property="article:published_time" content="2025-07-27T00:00:00+00:00">
    <meta property="article:modified_time" content="2025-07-27T00:00:00+00:00">
    <meta property="article:tag" content="LLMs">
    <meta property="article:tag" content="Apps">
    <meta property="article:tag" content="Python">


  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Building an AI version of myself">
  <meta name="twitter:description" content="How I built a persona-based LLM chatbot with self-evaluation.">


<link rel="stylesheet" href="/bootstrap-5/css/bootstrap.min.css" media="all"><link rel="stylesheet" href="/css/header.css" media="all">
<link rel="stylesheet" href="/css/footer.css" media="all">


<link rel="stylesheet" href="/css/theme.css" media="all">

<style>
    :root {
        --text-color: #343a40;
        --text-secondary-color: #5a5b5c;
        --text-link-color: #5a5b5c;
        --background-color: #eeeee4;
        --secondary-background-color: #ee8335;
        --primary-color: #5a5b5c;
        --secondary-color: #f8f9fa;

         
        --text-color-dark: #e4e6eb;
        --text-secondary-color-dark: #b0b3b8;
        --text-link-color-dark: #096cd6;
        --background-color-dark: #18191a;
        --secondary-background-color-dark: #212529;
        --primary-color-dark: #ffffff;
        --secondary-color-dark: #212529;
    }
    body {
        font-size: 1rem;
        font-weight: 400;
        line-height: 1.5;
        text-align: left;
    }

    html {
        background-color: var(--background-color) !important;
    }

    body::-webkit-scrollbar {
        height: 0px;
        width: 8px;
        background-color: var(--background-color);
    }

    ::-webkit-scrollbar-track {
        border-radius: 1rem;
    }

    ::-webkit-scrollbar-thumb {
        border-radius: 1rem;
        background: #b0b0b0;
        outline: 1px solid var(--background-color);
    }

    #search-content::-webkit-scrollbar {
        width: .5em;
        height: .1em;
        background-color: var(--background-color);
    }
</style>



<meta name="description" content="">
<link rel="stylesheet" href="/css/single.css">


<script defer src="/fontawesome-6/all-6.4.2.js"></script>


  
  

  <title>
Building an AI version of myself | Datahook: Helena

  </title>
</head>

<body class="light">
  
  
<script>
    let localStorageValue = localStorage.getItem("pref-theme");
    let mediaQuery = window.matchMedia('(prefers-color-scheme: dark)').matches;

    switch (localStorageValue) {
        case "dark":
            document.body.classList.add('dark');
            break;
        case "light":
            document.body.classList.remove('dark');
            break;
        default:
            if (mediaQuery) {
                document.body.classList.add('dark');
            }
            break;
    }
</script>




<script>
    var prevScrollPos = window.pageYOffset;
    window.addEventListener("scroll", function showHeaderOnScroll() {
        let profileHeaderElem = document.getElementById("profileHeader");
        let currentScrollPos = window.pageYOffset;
        let resetHeaderStyle = false;
        let showNavBarOnScrollUp =  true ;
        let showNavBar = showNavBarOnScrollUp ? prevScrollPos > currentScrollPos : currentScrollPos > 0;
        if (showNavBar) {
            profileHeaderElem.classList.add("showHeaderOnTop");
        } else {
            resetHeaderStyle = true;
        }
        if(currentScrollPos === 0) {
            resetHeaderStyle = true;
        }
        if(resetHeaderStyle) {
            profileHeaderElem.classList.remove("showHeaderOnTop");
        }
        prevScrollPos = currentScrollPos;
    });
</script>



<header id="profileHeader">
    <nav class="pt-3 navbar navbar-expand-lg animate">
        <div class="container-fluid mx-xs-2 mx-sm-5 mx-md-5 mx-lg-5">
            
            <a class="navbar-brand primary-font text-wrap" href="/">
                
                <img src="/favicon_dh.ico" width="30" height="30"
                    class="d-inline-block align-top">
                Data Hook
                
            </a>

            
                <div>
                    <input id="search" autocomplete="off" class="form-control mr-sm-2 d-none d-md-block" placeholder='Ctrl &#43; k to Search...'
                        aria-label="Search" oninput="searchOnChange(event)">
                </div>
            

            
            <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarContent"
                aria-controls="navbarContent" aria-expanded="false" aria-label="Toggle navigation">
                <svg aria-hidden="true" height="24" viewBox="0 0 16 16" version="1.1" width="24" data-view-component="true">
                    <path fill-rule="evenodd" d="M1 2.75A.75.75 0 011.75 2h12.5a.75.75 0 110 1.5H1.75A.75.75 0 011 2.75zm0 5A.75.75 0 011.75 7h12.5a.75.75 0 110 1.5H1.75A.75.75 0 011 7.75zM1.75 12a.75.75 0 100 1.5h12.5a.75.75 0 100-1.5H1.75z"></path>
                </svg>
            </button>

            
            <div class="collapse navbar-collapse text-wrap primary-font" id="navbarContent">
                <ul class="navbar-nav ms-auto text-center">
                    
                        <li class="nav-item navbar-text d-block d-md-none">
                            <div class="nav-link">
                                <input id="search" autocomplete="off" class="form-control mr-sm-2" placeholder='Ctrl &#43; k to Search...' aria-label="Search" oninput="searchOnChange(event)">
                            </div>
                        </li>
                    

                    

                    

                    

                    

                    

                    
                    <li class="nav-item navbar-text">
                        <a class="nav-link" href="/#contact"
                            aria-label="contact">
                            Contact
                        </a>
                    </li>
                    

                    

                    
                    
                    
                    
                    <li class="nav-item navbar-text">
                        <a class="nav-link" href="/cv/helena_hook_cv.pdf" title="Download CV">
                            
                            CV
                        </a>
                    </li>
                    
                    
                    
                    
                    <li class="nav-item navbar-text">
                        <a class="nav-link" href="/blogs" title="Blog posts">
                            
                            Blog
                        </a>
                    </li>
                    
                    

                    
                    <li class="nav-item navbar-text">
                        <a class="nav-link" href="/ab-calculator/" title="A/B Test Duration Calculator">
                            A/B test calculator
                        </a>
                    </li>

                    

                </ul>

            </div>
        </div>
    </nav>
</header>
<div id="content">
<section id="single">
  <div class="container">
    <div class="row justify-content-center">
      <div class="col-sm-12 col-md-12 col-lg-9">
        <div class="pr-lg-4">
          <div class="title mb-5">
            <h1 class="text-center mb-4">Building an AI version of myself</h1>
            <div class="text-center">
              
                Helena
                <small>|</small>
              
              Jul 27, 2025

              
              <span id="readingTime">
                min read
              </span>
              
            </div>
          </div>
          
          <div class="featured-image">
            <img class="img-fluid mx-auto d-block" src="/images/chatbot_post_cover.png" alt="Building an AI version of myself">
          </div>
          
          <article class="page-content  p-2">
          <p>How I built a persona-based LLM chatbot with self-evaluation.</p>
<p>This is a Chatbot I built with Gradio in Python hosted on <a href="https://huggingface.co/spaces/heleh/hele-experience-chatbot">Huggingface</a>, acting as me to answer questions about my skills and work experience. Code for the project can be seen <a href="https://huggingface.co/spaces/heleh/hele-experience-chatbot/blob/main/app.py">here</a>.</p>
<p>Read more below for a step by step guide on how it was built.</p>


<iframe
	src="https://heleh-hele-experience-chatbot.hf.space?__theme=light&embed=true"
  style="width:100%; height:620px; border:0; background: transparent;"
  allow="clipboard-write"
></iframe>

<h2 id="1-load-profile-data-pdf--summary">1. Load profile data (pdf + Summary)</h2>
<p>I read in my LinkedIn export and a short summary to give the model authentic, up-to-date context about me.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> pypdf <span style="color:#f92672">import</span> PdfReader
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>reader <span style="color:#f92672">=</span> PdfReader(<span style="color:#e6db74">&#34;me/linkedin.pdf&#34;</span>)
</span></span><span style="display:flex;"><span>linkedin <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> page <span style="color:#f92672">in</span> reader<span style="color:#f92672">.</span>pages:
</span></span><span style="display:flex;"><span>    text <span style="color:#f92672">=</span> page<span style="color:#f92672">.</span>extract_text()
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> text:
</span></span><span style="display:flex;"><span>        linkedin <span style="color:#f92672">+=</span> text
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">with</span> open(<span style="color:#e6db74">&#34;me/summary.txt&#34;</span>, <span style="color:#e6db74">&#34;r&#34;</span>, encoding<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;utf-8&#34;</span>) <span style="color:#66d9ef">as</span> f:
</span></span><span style="display:flex;"><span>    summary <span style="color:#f92672">=</span> f<span style="color:#f92672">.</span>read()
</span></span></code></pre></div><p><strong>Why:</strong> Grounding the model with my real experience reduces hallucinations and keeps answers consistent with my background.</p>
<h2 id="2-define-the-persona-and-system-prompt">2. Define the persona and system prompt</h2>
<p>I set the chatbot to “act as” me and embedded both data sources directly into the system message.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>name <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;Helena Hook&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>system_prompt <span style="color:#f92672">=</span> (
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;You are acting as </span><span style="color:#e6db74">{</span>name<span style="color:#e6db74">}</span><span style="color:#e6db74">...&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;</span><span style="color:#ae81ff">\n\n</span><span style="color:#e6db74">## Summary:</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">{</span>summary<span style="color:#e6db74">}</span><span style="color:#ae81ff">\n\n</span><span style="color:#e6db74">## LinkedIn Profile:</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">{</span>linkedin<span style="color:#e6db74">}</span><span style="color:#ae81ff">\n\n</span><span style="color:#e6db74">&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;With this context, please chat with the user, always staying in character as </span><span style="color:#e6db74">{</span>name<span style="color:#e6db74">}</span><span style="color:#e6db74">.&#34;</span>
</span></span><span style="display:flex;"><span>)
</span></span></code></pre></div><p><strong>Why:</strong> A strong system prompt + my materials gives the model guardrails (tone, audience, scope) and concrete facts.</p>
<h2 id="3-connect-to-the-primary-llm-openai">3. Connect to the primary LLM (OpenAI)</h2>
<p>This model produces the user-facing reply.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> openai <span style="color:#f92672">import</span> OpenAI
</span></span><span style="display:flex;"><span>openai <span style="color:#f92672">=</span> OpenAI()  <span style="color:#75715e"># reads OPENAI_API_KEY from env</span>
</span></span></code></pre></div><p><strong>Why:</strong> Keep the main chat model simple and fast (I used <code>gpt-4o-mini</code>).</p>
<h2 id="4-add-evaluator-gemini">4. Add evaluator (Gemini)</h2>
<p>I use a <strong>separate</strong> model to critique the first model’s reply before showing it to users.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> pydantic <span style="color:#f92672">import</span> BaseModel
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> os
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>gemini <span style="color:#f92672">=</span> OpenAI(
</span></span><span style="display:flex;"><span>    api_key<span style="color:#f92672">=</span>os<span style="color:#f92672">.</span>getenv(<span style="color:#e6db74">&#34;GOOGLE_API_KEY&#34;</span>),
</span></span><span style="display:flex;"><span>    base_url<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;https://generativelanguage.googleapis.com/v1beta/openai/&#34;</span>
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">Evaluation</span>(BaseModel):
</span></span><span style="display:flex;"><span>    is_acceptable: bool
</span></span><span style="display:flex;"><span>    feedback: str
</span></span></code></pre></div><p>I share the same context with the evaluator and ask it to judge the chatbot’s latest response in the ongoing conversation.:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">evaluator_user_prompt</span>(reply, message, history):
</span></span><span style="display:flex;"><span>    user_prompt <span style="color:#f92672">=</span> (
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Here&#39;s the conversation... </span><span style="color:#ae81ff">\n\n</span><span style="color:#e6db74">{</span>history<span style="color:#e6db74">}</span><span style="color:#ae81ff">\n\n</span><span style="color:#e6db74">&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Here&#39;s the latest message from the User: </span><span style="color:#ae81ff">\n\n</span><span style="color:#e6db74">{</span>message<span style="color:#e6db74">}</span><span style="color:#ae81ff">\n\n</span><span style="color:#e6db74">&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Here&#39;s the latest response from the Agent: </span><span style="color:#ae81ff">\n\n</span><span style="color:#e6db74">{</span>reply<span style="color:#e6db74">}</span><span style="color:#ae81ff">\n\n</span><span style="color:#e6db74">&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;Please evaluate the response, replying with whether it is acceptable and your feedback.&#34;</span>
</span></span><span style="display:flex;"><span>    )
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> user_prompt
</span></span></code></pre></div><p>Then I <strong>parse</strong> the evaluator’s output into the <code>Evaluation</code> schema:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">evaluate</span>(reply, message, history) <span style="color:#f92672">-&gt;</span> Evaluation:
</span></span><span style="display:flex;"><span>    messages <span style="color:#f92672">=</span> [
</span></span><span style="display:flex;"><span>        {<span style="color:#e6db74">&#34;role&#34;</span>: <span style="color:#e6db74">&#34;system&#34;</span>, <span style="color:#e6db74">&#34;content&#34;</span>: evaluator_system_prompt},
</span></span><span style="display:flex;"><span>        {<span style="color:#e6db74">&#34;role&#34;</span>: <span style="color:#e6db74">&#34;user&#34;</span>, <span style="color:#e6db74">&#34;content&#34;</span>: evaluator_user_prompt(reply, message, history)}
</span></span><span style="display:flex;"><span>    ]
</span></span><span style="display:flex;"><span>    response <span style="color:#f92672">=</span> gemini<span style="color:#f92672">.</span>beta<span style="color:#f92672">.</span>chat<span style="color:#f92672">.</span>completions<span style="color:#f92672">.</span>parse(
</span></span><span style="display:flex;"><span>        model<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;gemini-2.0-flash&#34;</span>,
</span></span><span style="display:flex;"><span>        messages<span style="color:#f92672">=</span>messages,
</span></span><span style="display:flex;"><span>        response_format<span style="color:#f92672">=</span>Evaluation
</span></span><span style="display:flex;"><span>    )
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> response<span style="color:#f92672">.</span>choices[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">.</span>message<span style="color:#f92672">.</span>parsed
</span></span></code></pre></div><p><strong>Why:</strong> Using a second model to check tone, accuracy, and professionalism catches weak answers before users see them. Pydantic keeps the evaluator’s output structured and reliable.</p>
<h2 id="5-if-rejected-help-the-main-model-improve-and-try-again">5. If rejected, help the main model improve and try again</h2>
<p>When the evaluator says the answer isn’t good enough, I update the main model’s instructions with:</p>
<ul>
<li>The bad answer, and</li>
<li>The evaluator’s reason for rejection</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">rerun</span>(reply, message, history, feedback):
</span></span><span style="display:flex;"><span>    updated_system_prompt <span style="color:#f92672">=</span> (
</span></span><span style="display:flex;"><span>        system_prompt
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">+</span> <span style="color:#e6db74">&#34;</span><span style="color:#ae81ff">\n\n</span><span style="color:#e6db74">## Previous answer rejected</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">You just tried to reply, but the quality control rejected your reply</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">+</span> <span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;## Your attempted answer:</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">{</span>reply<span style="color:#e6db74">}</span><span style="color:#ae81ff">\n\n</span><span style="color:#e6db74">&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">+</span> <span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;## Reason for rejection:</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">{</span>feedback<span style="color:#e6db74">}</span><span style="color:#ae81ff">\n\n</span><span style="color:#e6db74">&#34;</span>
</span></span><span style="display:flex;"><span>    )
</span></span><span style="display:flex;"><span>    messages <span style="color:#f92672">=</span> [{<span style="color:#e6db74">&#34;role&#34;</span>: <span style="color:#e6db74">&#34;system&#34;</span>, <span style="color:#e6db74">&#34;content&#34;</span>: updated_system_prompt}] <span style="color:#f92672">+</span> history <span style="color:#f92672">+</span> [{<span style="color:#e6db74">&#34;role&#34;</span>: <span style="color:#e6db74">&#34;user&#34;</span>, <span style="color:#e6db74">&#34;content&#34;</span>: message}]
</span></span><span style="display:flex;"><span>    response <span style="color:#f92672">=</span> openai<span style="color:#f92672">.</span>chat<span style="color:#f92672">.</span>completions<span style="color:#f92672">.</span>create(model<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;gpt-4o-mini&#34;</span>, messages<span style="color:#f92672">=</span>messages)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> response<span style="color:#f92672">.</span>choices[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">.</span>message<span style="color:#f92672">.</span>content
</span></span></code></pre></div><p><strong>Why:</strong> This creates a tight feedback loop where the main model learns what to fix and tries again.</p>
<h2 id="6-add-an-example-enforced-style-rule-keyword-trigger">6. Add an example enforced style rule (keyword trigger)</h2>
<p>If the user’s message contains the word <code>&quot;patent&quot;</code>, I force the reply to be in Pig Latin (just to demonstrate hard constraints).</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">chat</span>(message, history):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> <span style="color:#e6db74">&#34;patent&#34;</span> <span style="color:#f92672">in</span> message:
</span></span><span style="display:flex;"><span>        system <span style="color:#f92672">=</span> system_prompt <span style="color:#f92672">+</span> <span style="color:#e6db74">&#34;</span><span style="color:#ae81ff">\n\n</span><span style="color:#e6db74">Everything in your reply needs to be in pig latin ...&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">else</span>:
</span></span><span style="display:flex;"><span>        system <span style="color:#f92672">=</span> system_prompt
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">...</span>
</span></span></code></pre></div><p><strong>Why:</strong> Shows how to conditionally tighten style/format policies at runtime.</p>
<h2 id="7-full-message-flow-per-user-turn">7. Full message flow per user turn</h2>
<ol>
<li>Build the system prompt (Pig Latin variant if triggered).</li>
<li>Call the <strong>primary</strong> LLM to get a draft reply.</li>
<li>Send draft, user message, and conversation history to the <strong>evaluator</strong>.</li>
<li>If <code>evaluation.is_acceptable</code>:
<ul>
<li>Return the draft to the user.</li>
<li>Else, call <code>rerun(...)</code> with evaluator feedback and return the improved reply.</li>
</ul>
</li>
</ol>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>response <span style="color:#f92672">=</span> openai<span style="color:#f92672">.</span>chat<span style="color:#f92672">.</span>completions<span style="color:#f92672">.</span>create(model<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;gpt-4o-mini&#34;</span>, messages<span style="color:#f92672">=</span>messages)
</span></span><span style="display:flex;"><span>reply <span style="color:#f92672">=</span> response<span style="color:#f92672">.</span>choices[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">.</span>message<span style="color:#f92672">.</span>content
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>evaluation <span style="color:#f92672">=</span> evaluate(reply, message, history)
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">if</span> <span style="color:#f92672">not</span> evaluation<span style="color:#f92672">.</span>is_acceptable:
</span></span><span style="display:flex;"><span>    reply <span style="color:#f92672">=</span> rerun(reply, message, history, evaluation<span style="color:#f92672">.</span>feedback)
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">return</span> reply
</span></span></code></pre></div><p><strong>Why:</strong> This keeps latency reasonable (usually one pass) but upgrades quality automatically when needed.</p>
<h2 id="8-wrap-it-in-a-simple-ui-gradio">8. Wrap it in a simple UI (Gradio)</h2>
<p>I expose the chat loop as a web app with Gradio’s  <code>ChatInterface</code>.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> gradio <span style="color:#66d9ef">as</span> gr
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>gr<span style="color:#f92672">.</span>ChatInterface(
</span></span><span style="display:flex;"><span>    chat,
</span></span><span style="display:flex;"><span>    type<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;messages&#34;</span>,
</span></span><span style="display:flex;"><span>    title<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;Chatbot&#34;</span>,
</span></span><span style="display:flex;"><span>    theme<span style="color:#f92672">=</span>gr<span style="color:#f92672">.</span>themes<span style="color:#f92672">.</span>Soft(),
</span></span><span style="display:flex;"><span>    fill_height<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>
</span></span><span style="display:flex;"><span>)<span style="color:#f92672">.</span>launch()
</span></span></code></pre></div><p><strong>Why:</strong> Instant local demo and easy deployment to a small server.</p>
<h2 id="extensions-id-add-next">Extensions I’d Add Next</h2>
<ul>
<li><strong>Retrieval</strong>: Embed and index the PDF/summary for better grounding than a giant system prompt.</li>
<li><strong>Memory</strong>: Store common Q&amp;A and let the model cite sources.</li>
<li><strong>Analytics</strong>: Log evaluator feedback to see recurring failure modes.</li>
<li><strong>Tests</strong>: Scripted prompts that must pass the evaluator before deploys.</li>
</ul>
          </article>
        </div>
      </div>
      <div class="col-sm-12 col-md-12 col-lg-3">
        <div id="stickySideBar" class="sticky-sidebar">
          
          <aside class="toc">
              <h5>
                Table Of Contents
              </h5>
              <div class="toc-content">
                <nav id="TableOfContents">
  <ul>
    <li><a href="#1-load-profile-data-pdf--summary">1. Load profile data (pdf + Summary)</a></li>
    <li><a href="#2-define-the-persona-and-system-prompt">2. Define the persona and system prompt</a></li>
    <li><a href="#3-connect-to-the-primary-llm-openai">3. Connect to the primary LLM (OpenAI)</a></li>
    <li><a href="#4-add-evaluator-gemini">4. Add evaluator (Gemini)</a></li>
    <li><a href="#5-if-rejected-help-the-main-model-improve-and-try-again">5. If rejected, help the main model improve and try again</a></li>
    <li><a href="#6-add-an-example-enforced-style-rule-keyword-trigger">6. Add an example enforced style rule (keyword trigger)</a></li>
    <li><a href="#7-full-message-flow-per-user-turn">7. Full message flow per user turn</a></li>
    <li><a href="#8-wrap-it-in-a-simple-ui-gradio">8. Wrap it in a simple UI (Gradio)</a></li>
    <li><a href="#extensions-id-add-next">Extensions I’d Add Next</a></li>
  </ul>
</nav>
              </div>
          </aside>
          

          
          <aside class="tags">
            <h5>Tags</h5>
            <ul class="tags-ul list-unstyled list-inline">
              
              <li class="list-inline-item"><a href="https://hhook.github.io/tags/llms"
                target="_blank"
              >LLMs</a></li>
              
              <li class="list-inline-item"><a href="https://hhook.github.io/tags/apps"
                target="_blank"
              >apps</a></li>
              
              <li class="list-inline-item"><a href="https://hhook.github.io/tags/python"
                target="_blank"
              >python</a></li>
              
            </ul>
          </aside>
          

          
          <aside class="social">
            <h5>Social</h5>
            <div class="social-content">
              <ul class="list-inline">
                <li class="list-inline-item text-center">
                  <a target="_blank" href="https://www.linkedin.com/shareArticle?mini=true&url=https%3a%2f%2fhhook.github.io%2fblogs%2f07_helena_chatbot%2f">
                    <i class="fab fa-linkedin"></i>
                  </a>
                </li>
                <li class="list-inline-item text-center">
                  <a target="_blank" href="https://twitter.com/share?text=Building%20an%20AI%20version%20of%20myself&url=https%3a%2f%2fhhook.github.io%2fblogs%2f07_helena_chatbot%2f">
                    <i class="fab fa-twitter"></i>
                  </a>
                </li>
                <li class="list-inline-item text-center">
                  <a target="_blank" href="https://api.whatsapp.com/send?text=Building%20an%20AI%20version%20of%20myself: https%3a%2f%2fhhook.github.io%2fblogs%2f07_helena_chatbot%2f">
                    <i class="fab fa-whatsapp"></i>
                  </a>
                </li>
                <li class="list-inline-item text-center">
                  <a target="_blank" href='mailto:?subject=Building%20an%20AI%20version%20of%20myself&amp;body=Check%20out%20this%20site https%3a%2f%2fhhook.github.io%2fblogs%2f07_helena_chatbot%2f'>
                    <i class="fa fa-envelope"></i>
                  </a>
                </li>
              </ul>
            </div>
          </aside>
          
        </div>
      </div>
    </div>
    <div class="row">
      <div class="col-sm-12 col-md-12 col-lg-9 p-4">
        
      </div>
    </div>
  </div>
  <button class="p-2 px-3" onclick="topFunction()" id="topScroll">
    <i class="fas fa-angle-up"></i>
  </button>
</section>


<div class="progress">
  <div id="scroll-progress-bar" class="progress-bar" role="progressbar" aria-valuenow="0" aria-valuemin="0" aria-valuemax="100"></div>
</div>
<Script src="/js/scrollProgressBar.js"></script>


<script>
  var topScroll = document.getElementById("topScroll");
  window.onscroll = function() {scrollFunction()};

  function scrollFunction() {
    if (document.body.scrollTop > 20 || document.documentElement.scrollTop > 20) {
      topScroll.style.display = "block";
    } else {
      topScroll.style.display = "none";
    }
  }

  function topFunction() {
    document.body.scrollTop = 0;
    document.documentElement.scrollTop = 0;
  }

  
  let stickySideBarElem = document.getElementById("stickySideBar");
  let stickyNavBar =  true ;
  if(stickyNavBar) {
    let headerElem = document.getElementById("profileHeader");
    let headerHeight = headerElem.offsetHeight + 15;
    stickySideBarElem.style.top = headerHeight + "px";
  } else {
    stickySideBarElem.style.top = "50px";
  }
</script>


<script src="/js/readingTime.js"></script>



  </div><footer>
    
    

    
<section id="contact" class="py-5">
    <div class="container">
        <h3 class="text-center">Get in Touch</h3>
        <div class="px-0 px-md-5 px-lg-5">
            <div class="row justify-content-center px-md-5">
                <div class="col-md-8 py-3">
                    <div class="text-center">
                        My inbox is always open. Whether you have a question or just want to say hi, I’ll try my best to get back to you!
                    </div>
                    
                    <div class="text-center pt-3">
                        <a 
                            href='
                                    mailto:helena@datahook.co.uk
                                  '
                            target="_blank"
                            class="btn"
                        >
                            Mail me
                        </a>
                    </div>
                    
                </div>
            </div>
        </div>
    </div>
    <div id="contact-form-status"></div>
</section>


<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="check-circle-fill" viewBox="0 0 16 16">
    <path d="M16 8A8 8 0 1 1 0 8a8 8 0 0 1 16 0zm-3.97-3.03a.75.75 0 0 0-1.08.022L7.477 9.417 5.384 7.323a.75.75 0 0 0-1.06 1.06L6.97 11.03a.75.75 0 0 0 1.079-.02l3.992-4.99a.75.75 0 0 0-.01-1.05z"/>
  </symbol>
  <symbol id="info-fill" viewBox="0 0 16 16">
    <path d="M8 16A8 8 0 1 0 8 0a8 8 0 0 0 0 16zm.93-9.412-1 4.705c-.07.34.029.533.304.533.194 0 .487-.07.686-.246l-.088.416c-.287.346-.92.598-1.465.598-.703 0-1.002-.422-.808-1.319l.738-3.468c.064-.293.006-.399-.287-.47l-.451-.081.082-.381 2.29-.287zM8 5.5a1 1 0 1 1 0-2 1 1 0 0 1 0 2z"/>
  </symbol>
  <symbol id="exclamation-triangle-fill" viewBox="0 0 16 16">
    <path d="M8.982 1.566a1.13 1.13 0 0 0-1.96 0L.165 13.233c-.457.778.091 1.767.98 1.767h13.713c.889 0 1.438-.99.98-1.767L8.982 1.566zM8 5c.535 0 .954.462.9.995l-.35 3.507a.552.552 0 0 1-1.1 0L7.1 5.995A.905.905 0 0 1 8 5zm.002 6a1 1 0 1 1 0 2 1 1 0 0 1 0-2z"/>
  </symbol>
</svg>
<div class="text-center pt-2">
    

    

    

    

    
</div><div class="container py-4">
    <div class="row justify-content-center">
        <div class="col-md-4 text-center">
            
                <div class="pb-2">
                    <a href="https://hhook.github.io/" title="Datahook: Helena">
                        <img alt="Footer logo" src="/favicon_dh.ico"
                            height="40px" width="40px">
                    </a>
                </div>
            
            &copy; 2026  All rights reserved
            <div class="text-secondary">
                Made with
                <span class="text-danger">
                    &#10084;
                </span>
                and
                <a href="https://github.com/gurusabarish/hugo-profile" target="_blank"
                    title="Designed and developed by gurusabarish">
                    Hugo Profile
                </a>
            </div>
        </div>
    </div>
</div>
</footer><script src="/bootstrap-5/js/bootstrap.bundle.min.js"></script>
<script>
    if (document.body.className.includes("dark")) {
        document.body.classList.remove('dark');
        localStorage.setItem("pref-theme", 'light');
    }
</script>




    <script src="/js/search.js"></script>











  <section id="search-content" class="py-2">
    <div class="container" id="search-results"></div>
  </section>
</body>

</html>
